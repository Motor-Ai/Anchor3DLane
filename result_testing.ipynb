{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d9a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anchor3dlane/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import torch\n",
    "# from testing.infer import *\n",
    "import os\n",
    "import numpy as np\n",
    "from mmcv.utils import Config, DictAction, get_git_hash\n",
    "from mmseg.models import build_lanedetector\n",
    "from mmengine.model import revert_sync_batchnorm\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732e91bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 16:09:24,167 - mmcv - INFO - initialize ResNetV1c with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor: 4431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 16:09:24,245 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,247 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,249 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,250 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,252 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,254 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,256 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,258 - mmcv - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}\n",
      "2024-05-02 16:09:24,264 - mmcv - INFO - \n",
      "backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,264 - mmcv - INFO - \n",
      "backbone.stem.1.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,265 - mmcv - INFO - \n",
      "backbone.stem.1.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,266 - mmcv - INFO - \n",
      "backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,266 - mmcv - INFO - \n",
      "backbone.stem.4.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,267 - mmcv - INFO - \n",
      "backbone.stem.4.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,267 - mmcv - INFO - \n",
      "backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,268 - mmcv - INFO - \n",
      "backbone.stem.7.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,268 - mmcv - INFO - \n",
      "backbone.stem.7.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,269 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,269 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,270 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,271 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,271 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,271 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,272 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,272 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,273 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,273 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,274 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,275 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,275 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,276 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,277 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,277 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,277 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,278 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,278 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,279 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,279 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,280 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,280 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,281 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,281 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,281 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,282 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,282 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,283 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,283 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,284 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,284 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,286 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,287 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,287 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,287 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,288 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,288 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,289 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,290 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,290 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,291 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,291 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,291 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,292 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,292 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,293 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,293 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,293 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,294 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,294 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,294 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,295 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,295 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,296 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,296 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2024-05-02 16:09:24,296 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,298 - mmcv - INFO - \n",
      "input_proj.weight - torch.Size([64, 512, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,299 - mmcv - INFO - \n",
      "input_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,299 - mmcv - INFO - \n",
      "transformer_layer.self_attn.in_proj_weight - torch.Size([192, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,300 - mmcv - INFO - \n",
      "transformer_layer.self_attn.in_proj_bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,300 - mmcv - INFO - \n",
      "transformer_layer.self_attn.out_proj.weight - torch.Size([64, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,300 - mmcv - INFO - \n",
      "transformer_layer.self_attn.out_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,301 - mmcv - INFO - \n",
      "transformer_layer.linear1.weight - torch.Size([128, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,302 - mmcv - INFO - \n",
      "transformer_layer.linear1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,302 - mmcv - INFO - \n",
      "transformer_layer.linear2.weight - torch.Size([64, 128]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,302 - mmcv - INFO - \n",
      "transformer_layer.linear2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,303 - mmcv - INFO - \n",
      "transformer_layer.norm1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,303 - mmcv - INFO - \n",
      "transformer_layer.norm1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,304 - mmcv - INFO - \n",
      "transformer_layer.norm2.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,304 - mmcv - INFO - \n",
      "transformer_layer.norm2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,304 - mmcv - INFO - \n",
      "anchor_projection.weight - torch.Size([64, 64, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,305 - mmcv - INFO - \n",
      "anchor_projection.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,305 - mmcv - INFO - \n",
      "cls_layer.0.layer.0.weight - torch.Size([640, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,306 - mmcv - INFO - \n",
      "cls_layer.0.layer.0.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,306 - mmcv - INFO - \n",
      "cls_layer.0.layer.2.weight - torch.Size([640, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,306 - mmcv - INFO - \n",
      "cls_layer.0.layer.2.bias - torch.Size([640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,308 - mmcv - INFO - \n",
      "cls_layer.0.layer.4.weight - torch.Size([21, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,308 - mmcv - INFO - \n",
      "cls_layer.0.layer.4.bias - torch.Size([21]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,309 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.0.weight - torch.Size([64, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,309 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,310 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.2.weight - torch.Size([64, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,310 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,311 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.4.weight - torch.Size([20, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,311 - mmcv - INFO - \n",
      "reg_x_layer.0.layer.4.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,311 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.0.weight - torch.Size([64, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,312 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,312 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.2.weight - torch.Size([64, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,313 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,313 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.4.weight - torch.Size([20, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,313 - mmcv - INFO - \n",
      "reg_z_layer.0.layer.4.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,314 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.0.weight - torch.Size([64, 640]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,314 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,315 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.2.weight - torch.Size([64, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,315 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,316 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.4.weight - torch.Size([20, 64]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n",
      "2024-05-02 16:09:24,316 - mmcv - INFO - \n",
      "reg_vis_layer.0.layer.4.bias - torch.Size([20]): \n",
      "The value is the same before and after calling `init_weights` of Anchor3DLane  \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_resample: True\n",
      "Now loading annotations...\n",
      "after load annotation\n",
      "find 8800 samples in data/OpenLane/data_lists/training.txt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config.fromfile(\"/home/ec2-user/vardeep_ws/Anchor3DLane/configs/test_config.py\")\n",
    "\n",
    "model = build_lanedetector(cfg.model)\n",
    "\n",
    "model.init_weights()\n",
    "\n",
    "model = revert_sync_batchnorm(model)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "loader_cfg = dict(\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=1,\n",
    "    dist=False,\n",
    "    # seed=cfg.seed,\n",
    "    drop_last=True,\n",
    "    shuffle=cfg.data_shuffle,\n",
    "    persistent_workers=False)\n",
    "# The overall dataloader settings\n",
    "loader_cfg.update({\n",
    "    k: v\n",
    "    for k, v in cfg.data.items() if k not in [\n",
    "        'train', 'val', 'test', 'train_dataloader', 'val_dataloader',\n",
    "        'test_dataloader'\n",
    "    ]\n",
    "})\n",
    "checkpoint = torch.load(\"/home/ec2-user/vardeep_ws/Anchor3DLane/work_dir/openlane.pth\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2236c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('data.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "for i in range(len(data['img_metas']['ori_shape'])):\n",
    "    data['img_metas']['ori_shape'][i] = data['img_metas']['ori_shape'][i].cpu()\n",
    "for i in range(len(data['gt_3dlanes'])):\n",
    "    data['gt_3dlanes'][i] = data['gt_3dlanes'][i].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ea52fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 360, 480])\n"
     ]
    }
   ],
   "source": [
    "test_img = data['img'].squeeze()\n",
    "print(data['img'].shape)\n",
    "# test_img = (test_img - test_img.min()) / (test_img.max() - test_img.min())\n",
    "# plt.imshow(test_img.permute(1, 2, 0))\n",
    "# plt.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459111bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_proposals': tensor([[[ 0.0000,  0.0000,  0.0000,  ..., -4.3536, -4.3624, -5.6798],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -4.0584, -4.0440, -3.3012],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -3.9387, -3.9319, -4.1316],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -3.8156, -3.8204, -5.4381],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -4.2803, -4.2727, -5.3367],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -3.6509, -3.6293, -5.6673]]],\n",
      "       grad_fn=<CopySlices>), 'anchors': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'proposals_list': [(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "         -1.8159e+00, -1.7828e+00, -1.8062e+00, -1.7638e+00, -1.7371e+00,\n",
      "         -1.7145e+00, -1.6817e+00, -1.6622e+00, -1.6703e+00, -1.6672e+00,\n",
      "         -1.6608e+00, -1.6775e+00, -1.7302e+00, -1.7596e+00, -1.7816e+00,\n",
      "         -1.7917e+00, -1.7778e+00, -1.7677e+00, -1.6974e+00, -1.6693e+00,\n",
      "         -1.1278e-02, -4.4519e-03,  2.0931e-02,  3.2390e-02,  6.0466e-02,\n",
      "          8.6973e-02,  9.9983e-02,  1.3050e-01,  1.4310e-01,  1.5150e-01,\n",
      "          1.7146e-01,  1.9230e-01,  2.0029e-01,  1.9717e-01,  2.1369e-01,\n",
      "          2.2949e-01,  2.3502e-01,  2.5053e-01,  2.3835e-01,  2.6405e-01,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.0648e+00,  5.6361e+00, -1.7239e+01, -1.2062e+01, -1.4932e+01,\n",
      "         -1.2670e+01, -1.5969e+01, -7.6940e+00, -1.6391e+01, -8.8670e+00,\n",
      "         -8.3979e+00, -1.9264e+01, -1.6926e+01, -2.1540e+01, -2.1535e+01,\n",
      "         -2.1613e+01, -2.1643e+01, -2.1546e+01, -2.1551e+01, -2.1528e+01,\n",
      "         -9.0124e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "         -4.1071e+00, -4.8969e+00, -5.2697e+00, -5.4585e+00, -5.5490e+00,\n",
      "         -5.6210e+00, -5.7492e+00, -5.6515e+00, -5.5688e+00, -5.5465e+00,\n",
      "         -5.6016e+00, -5.7849e+00, -5.8777e+00, -5.8616e+00, -6.0023e+00,\n",
      "         -6.1424e+00, -6.2962e+00, -6.4168e+00, -6.5067e+00, -6.5976e+00,\n",
      "          1.6915e-01,  9.8493e-02,  5.0420e-02, -1.2961e-02, -3.8904e-02,\n",
      "         -4.8213e-02, -3.6970e-02, -4.4022e-02, -7.6022e-02, -8.1857e-02,\n",
      "         -7.7743e-02, -9.2115e-02, -9.4529e-02, -1.0366e-01, -1.0130e-01,\n",
      "         -1.1537e-01, -1.3666e-01, -1.4423e-01, -1.8570e-01, -2.1689e-01,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.1781e+00,  5.3281e+00, -1.3682e+01, -1.2622e+01, -1.3086e+01,\n",
      "         -1.3097e+01, -1.1143e+01, -1.2147e+01, -1.1460e+01, -9.4641e+00,\n",
      "         -1.1646e+01, -1.6771e+01, -7.8769e+00, -1.5214e+01, -1.5179e+01,\n",
      "         -1.5296e+01, -1.5247e+01, -1.5250e+01, -1.5276e+01, -1.5256e+01,\n",
      "         -9.9632e+00]], grad_fn=<IndexBackward>), tensor([[ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000, -1.4509, -1.5382, -1.6255,\n",
      "         -1.7127, -1.8000, -1.8873, -1.9746, -2.0618, -2.1491, -2.2364, -2.3237,\n",
      "         -2.4109, -2.4982, -2.5855, -2.6728, -2.7600, -2.8473, -2.9346, -3.0219,\n",
      "         -3.1091,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000, -4.3529, -4.6150, -4.8770,\n",
      "         -5.1391, -5.4011, -5.6631, -5.9252, -6.1872, -6.4493, -6.7113, -6.9733,\n",
      "         -7.2354, -7.4974, -7.7595, -8.0215, -8.2835, -8.5456, -8.8076, -9.0696,\n",
      "         -9.3317,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000]]), tensor([2101, 1878]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anchor3dlane/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/opt/conda/envs/anchor3dlane/lib/python3.9/site-packages/torch/nn/functional.py:3981: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_out = model(**data)\n",
    "print(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e381e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_filtered_out = np.load(\"engine_res.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b55eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filtered_out = model_out['proposals_list'][0][0].detach().numpy().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26a3580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01127755 -0.00445186  0.02093108  0.03239022  0.06046604  0.08697284\n",
      "   0.09998263  0.13050224  0.14310032  0.15150017  0.17145963  0.19230302\n",
      "   0.20028634  0.19716918  0.21368638  0.22949193  0.23501706  0.25053477\n",
      "   0.2383475   0.26405343]]\n"
     ]
    }
   ],
   "source": [
    "print(model_filtered_out[:, 25:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e75423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_axis0 = (np.square(engine_filtered_out - model_filtered_out)).mean(axis=0)\n",
    "Error_axis1 = (np.square(engine_filtered_out - model_filtered_out)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb024d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fe7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11046792]\n"
     ]
    }
   ],
   "source": [
    "print(Error_axis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ebedf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the output\n",
    "x = (model_filtered_out[:, 5:25]).squeeze()\n",
    "z = (model_filtered_out[:, 25:45]).squeeze()\n",
    "y = (np.linspace(1, 20, 20) * 5)\n",
    "\n",
    "x2 = (model_filtered_out[:, 86+5:86+25]).squeeze()\n",
    "z2 = (model_filtered_out[:, 86+25:86+45]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0c250ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Y')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_xticks([-0.1,-0.2, -0.5, -1, 0, 2, 4, 6])\n",
    "ax.set_yticks([-0.1, -0.2, -0.3, -0.5, -0.7, 2, 4, 6])\n",
    "ax.set_zticks([-0.1, -0.2, -0.5, 0, 2, 4, 6])\n",
    "\n",
    "ax.axes.set_xlim3d(left=0.2, right=9.8) \n",
    "ax.axes.set_ylim3d(bottom=0.2, top=9.8) \n",
    "ax.axes.set_zlim3d(bottom=0.2, top=9.8) \n",
    "\n",
    "ax.plot(x, y , z)\n",
    "ax.plot(x2, y, z2)\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6042e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Torch Output [without vis filter]')\n",
    "plt.savefig('assets/torch_without_vis_filter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abfd4678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,   0.        ,   1.        ,\n",
       "         0.        ,  -1.8159149 ,  -1.7827749 ,  -1.8061696 ,\n",
       "        -1.763845  ,  -1.7371167 ,  -1.7145038 ,  -1.6817397 ,\n",
       "        -1.6621883 ,  -1.6703012 ,  -1.6671634 ,  -1.6607778 ,\n",
       "        -1.6775253 ,  -1.7301773 ,  -1.7595541 ,  -1.7815778 ,\n",
       "        -1.7917117 ,  -1.7778251 ,  -1.767652  ,  -1.6973653 ,\n",
       "        -1.669321  ,  -0.01127756,  -0.00445189,   0.02093107,\n",
       "         0.0323902 ,   0.06046601,   0.08697283,   0.09998262,\n",
       "         0.13050224,   0.14310029,   0.15150017,   0.17145965,\n",
       "         0.19230297,   0.2002863 ,   0.19716918,   0.21368635,\n",
       "         0.2294919 ,   0.235017  ,   0.25053477,   0.23834744,\n",
       "         0.2640534 ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   2.0647824 ,   5.6360874 , -17.238758  ,\n",
       "       -12.062073  , -14.931803  , -12.670265  , -15.968508  ,\n",
       "        -7.6940465 , -16.391445  ,  -8.867006  ,  -8.397911  ,\n",
       "       -19.264225  , -16.92589   , -21.540443  , -21.534946  ,\n",
       "       -21.612595  , -21.642769  , -21.546318  , -21.551044  ,\n",
       "       -21.528236  ,  -9.012398  ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered_out[0][:86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33ff15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01127756, -0.00445189,  0.02093107,  0.0323902 ,  0.06046601,\n",
       "        0.08697283,  0.09998262,  0.13050224,  0.14310029,  0.15150017,\n",
       "        0.17145965,  0.19230297,  0.2002863 ,  0.19716918,  0.21368635,\n",
       "        0.2294919 ,  0.235017  ,  0.25053477,  0.23834744,  0.2640534 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c2e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
